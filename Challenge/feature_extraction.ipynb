{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainpath = '../data/kaggle-train-small/audio/'\n",
    "trainpath = '../data/kaggle-train/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsouza/Documents/envs/python_env/lib/python3.6/site-packages/librosa/core/pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: 1000:\n",
      "processing file: 2000:\n",
      "processing file: 3000:\n",
      "processing file: 4000:\n",
      "processing file: 5000:\n",
      "processing file: 6000:\n",
      "processing file: 7000:\n",
      "processing file: 8000:\n",
      "processing file: 9000:\n",
      "processing file: 10000:\n",
      "processing file: 11000:\n",
      "processing file: 12000:\n",
      "processing file: 13000:\n",
      "processing file: 14000:\n",
      "processing file: 15000:\n",
      "processing file: 16000:\n",
      "processing file: 17000:\n",
      "processing file: 18000:\n",
      "processing file: 19000:\n",
      "processing file: 20000:\n",
      "processing file: 21000:\n",
      "processing file: 22000:\n",
      "processing file: 23000:\n",
      "processing file: 24000:\n",
      "processing file: 25000:\n",
      "processing file: 26000:\n",
      "processing file: 27000:\n",
      "processing file: 28000:\n",
      "processing file: 29000:\n",
      "processing file: 30000:\n",
      "processing file: 31000:\n",
      "processing file: 32000:\n",
      "processing file: 33000:\n",
      "processing file: 34000:\n",
      "processing file: 35000:\n",
      "processing file: 36000:\n",
      "processing file: 37000:\n",
      "processing file: 38000:\n",
      "processing file: 39000:\n",
      "processing file: 40000:\n",
      "processing file: 41000:\n",
      "processing file: 42000:\n",
      "processing file: 43000:\n",
      "processing file: 44000:\n",
      "processing file: 45000:\n",
      "processing file: 46000:\n",
      "processing file: 47000:\n",
      "processing file: 48000:\n",
      "processing file: 49000:\n",
      "processing file: 50000:\n",
      "processing file: 51000:\n",
      "processing file: 52000:\n",
      "processing file: 53000:\n",
      "processing file: 54000:\n",
      "processing file: 55000:\n",
      "processing file: 56000:\n",
      "processing file: 57000:\n",
      "processing file: 58000:\n",
      "processing file: 59000:\n",
      "processing file: 60000:\n",
      "processing file: 61000:\n",
      "processing file: 62000:\n",
      "processing file: 63000:\n",
      "processing file: 64000:\n",
      "processing file: 65000:\n",
      "processing file: 66000:\n",
      "processing file: 67000:\n",
      "processing file: 68000:\n",
      "processing file: 69000:\n",
      "processing file: 70000:\n",
      "processing file: 71000:\n",
      "processing file: 72000:\n",
      "processing file: 73000:\n",
      "processing file: 74000:\n",
      "processing file: 75000:\n",
      "processing file: 76000:\n",
      "processing file: 77000:\n",
      "processing file: 78000:\n",
      "processing file: 79000:\n",
      "processing file: 80000:\n",
      "processing file: 81000:\n",
      "processing file: 82000:\n",
      "processing file: 83000:\n",
      "processing file: 84000:\n",
      "processing file: 85000:\n",
      "processing file: 86000:\n",
      "processing file: 87000:\n",
      "processing file: 88000:\n",
      "processing file: 89000:\n",
      "processing file: 90000:\n",
      "processing file: 91000:\n",
      "processing file: 92000:\n",
      "processing file: 93000:\n",
      "processing file: 94000:\n",
      "processing file: 95000:\n",
      "processing file: 96000:\n",
      "processing file: 97000:\n",
      "processing file: 98000:\n",
      "processing file: 99000:\n",
      "processing file: 100000:\n",
      "processing file: 101000:\n",
      "processing file: 102000:\n",
      "processing file: 103000:\n",
      "processing file: 104000:\n",
      "processing file: 105000:\n",
      "processing file: 106000:\n",
      "processing file: 107000:\n",
      "processing file: 108000:\n",
      "processing file: 109000:\n",
      "processing file: 110000:\n",
      "processing file: 111000:\n",
      "processing file: 112000:\n",
      "processing file: 113000:\n",
      "processing file: 114000:\n",
      "processing file: 115000:\n",
      "processing file: 116000:\n",
      "processing file: 117000:\n",
      "processing file: 118000:\n",
      "processing file: 119000:\n",
      "processing file: 120000:\n",
      "processing file: 121000:\n",
      "processing file: 122000:\n",
      "processing file: 123000:\n",
      "processing file: 124000:\n",
      "processing file: 125000:\n",
      "processing file: 126000:\n",
      "processing file: 127000:\n",
      "processing file: 128000:\n",
      "processing file: 129000:\n",
      "processing file: 130000:\n",
      "processing file: 131000:\n",
      "processing file: 132000:\n",
      "processing file: 133000:\n",
      "processing file: 134000:\n",
      "processing file: 135000:\n",
      "processing file: 136000:\n",
      "processing file: 137000:\n",
      "processing file: 138000:\n",
      "processing file: 139000:\n",
      "processing file: 140000:\n",
      "processing file: 141000:\n",
      "processing file: 142000:\n",
      "processing file: 143000:\n",
      "processing file: 144000:\n",
      "processing file: 145000:\n",
      "processing file: 146000:\n",
      "processing file: 147000:\n",
      "processing file: 148000:\n",
      "processing file: 149000:\n",
      "processing file: 150000:\n",
      "processing file: 151000:\n",
      "processing file: 152000:\n",
      "processing file: 153000:\n",
      "processing file: 154000:\n",
      "processing file: 155000:\n",
      "processing file: 156000:\n",
      "processing file: 157000:\n",
      "processing file: 158000:\n",
      "processing file: 159000:\n",
      "processing file: 160000:\n",
      "processing file: 161000:\n",
      "processing file: 162000:\n",
      "processing file: 163000:\n",
      "processing file: 164000:\n",
      "processing file: 165000:\n",
      "processing file: 166000:\n",
      "processing file: 167000:\n",
      "processing file: 168000:\n",
      "processing file: 169000:\n",
      "processing file: 170000:\n",
      "processing file: 171000:\n",
      "processing file: 172000:\n",
      "processing file: 173000:\n",
      "processing file: 174000:\n",
      "processing file: 175000:\n",
      "processing file: 176000:\n",
      "processing file: 177000:\n",
      "processing file: 178000:\n",
      "processing file: 179000:\n",
      "processing file: 180000:\n",
      "processing file: 181000:\n",
      "processing file: 182000:\n",
      "processing file: 183000:\n",
      "processing file: 184000:\n",
      "processing file: 185000:\n",
      "processing file: 186000:\n",
      "processing file: 187000:\n",
      "processing file: 188000:\n",
      "processing file: 189000:\n",
      "processing file: 190000:\n",
      "processing file: 191000:\n",
      "processing file: 192000:\n",
      "processing file: 193000:\n",
      "processing file: 194000:\n",
      "processing file: 195000:\n",
      "processing file: 196000:\n",
      "processing file: 197000:\n",
      "processing file: 198000:\n",
      "processing file: 199000:\n",
      "processing file: 200000:\n",
      "processing file: 201000:\n",
      "processing file: 202000:\n",
      "processing file: 203000:\n",
      "processing file: 204000:\n",
      "processing file: 205000:\n",
      "processing file: 206000:\n",
      "processing file: 207000:\n",
      "processing file: 208000:\n",
      "processing file: 209000:\n",
      "processing file: 210000:\n",
      "processing file: 211000:\n",
      "processing file: 212000:\n",
      "processing file: 213000:\n",
      "processing file: 214000:\n",
      "processing file: 215000:\n",
      "processing file: 216000:\n",
      "processing file: 217000:\n",
      "processing file: 218000:\n",
      "processing file: 219000:\n",
      "processing file: 220000:\n",
      "processing file: 221000:\n",
      "processing file: 222000:\n",
      "processing file: 223000:\n",
      "processing file: 224000:\n",
      "processing file: 225000:\n",
      "processing file: 226000:\n",
      "processing file: 227000:\n",
      "processing file: 228000:\n",
      "processing file: 229000:\n",
      "processing file: 230000:\n",
      "processing file: 231000:\n",
      "processing file: 232000:\n",
      "processing file: 233000:\n",
      "processing file: 234000:\n",
      "processing file: 235000:\n",
      "processing file: 236000:\n",
      "processing file: 237000:\n",
      "processing file: 238000:\n",
      "processing file: 239000:\n",
      "processing file: 240000:\n",
      "processing file: 241000:\n",
      "processing file: 242000:\n",
      "processing file: 243000:\n",
      "processing file: 244000:\n",
      "processing file: 245000:\n",
      "processing file: 246000:\n",
      "processing file: 247000:\n",
      "processing file: 248000:\n",
      "processing file: 249000:\n",
      "processing file: 250000:\n",
      "processing file: 251000:\n",
      "processing file: 252000:\n",
      "processing file: 253000:\n",
      "processing file: 254000:\n",
      "processing file: 255000:\n",
      "processing file: 256000:\n",
      "processing file: 257000:\n",
      "processing file: 258000:\n",
      "processing file: 259000:\n",
      "processing file: 260000:\n",
      "processing file: 261000:\n",
      "processing file: 262000:\n",
      "processing file: 263000:\n",
      "processing file: 264000:\n",
      "processing file: 265000:\n",
      "processing file: 266000:\n",
      "processing file: 267000:\n",
      "processing file: 268000:\n",
      "processing file: 269000:\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "files = os.listdir(trainpath)\n",
    "#files = files[0:10000]\n",
    "stft = []\n",
    "rmse = []\n",
    "spec_cent = []\n",
    "spec_bw = []\n",
    "rolloff = []\n",
    "zcr = []\n",
    "mfcc = []\n",
    "\n",
    "for idx, f in enumerate(files):\n",
    "    filename = os.path.join(trainpath, str(f))\n",
    "    y, sr = librosa.load(filename, mono=True, duration=120)\n",
    "    stft.append(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    #rmse.append(librosa.feature.rms(y=y))\n",
    "    #spec_cent.append(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    #spec_bw.append(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    #rolloff.append(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    #zcr.append(librosa.feature.zero_crossing_rate(y))\n",
    "    #mfcc.append(librosa.feature.mfcc(y=y, sr=sr))\n",
    "    if idx%5000 == 0:\n",
    "        print(f'processing file: {idx}')\n",
    "    \n",
    "stft = np.array(stft)\n",
    "#rmse = np.array(rmse)\n",
    "#spec_cent = np.array(spec_cent)\n",
    "#rolloff = np.array(rolloff)\n",
    "#zcr = np.array(zcr)\n",
    "#mfcc = np.array(mfcc)\n",
    "\n",
    "np.save('./stft.numpy', stft)\n",
    "#np.save('./rmse.numpy', rmse)\n",
    "#np.save('./spec_cent.numpy', spec_cent)\n",
    "#np.save('./rolloff.numpy', rolloff)\n",
    "#np.save('./zcr.numpy', zcr)\n",
    "#np.save('./mfcc.numpy', mfcc)\n",
    "\n",
    "    \n",
    "print(\"Extracting the features took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = np.load('./stft.numpy')\n",
    "rmse = np.load('./rmse.numpy')\n",
    "spec_cent = np.load('./spec_cent.numpy')\n",
    "rolloff = np.load('./rolloff.numpy')\n",
    "zcr = np.load('./zcr.numpy')\n",
    "mfcc = np.load('./mfcc.numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(files, columns=['filename'])\n",
    "df_train['audiotype'] = df_train['filename'].str.extract(pat = '_([a-z]*)_')\n",
    "df_train['instrument'] = df_train['filename'].str.extract(pat = '^([a-z]*)_')\n",
    "df_train['chroma_stft_mean'] = np.mean(stft, axis=(1,2))\n",
    "df_train['chroma_stft_std'] = np.std(stft, axis=(1,2))\n",
    "df_train['rmse_mean'] = np.mean(rmse, axis=(1,2))\n",
    "df_train['rmse_std'] = np.std(rmse, axis=(1,2))\n",
    "df_train['spec_cent_mean'] = np.mean(spec_cent, axis=(1,2))\n",
    "df_train['spec_cent_std'] = np.std(spec_cent, axis=(1,2))\n",
    "df_train['spec_bw_mean'] = np.mean(spec_bw, axis=(1,2))\n",
    "df_train['spec_bw_std'] = np.std(spec_bw, axis=(1,2))\n",
    "df_train['rolloff_mean'] = np.mean(rolloff, axis=(1,2))\n",
    "df_train['rolloff_std'] = np.std(rolloff, axis=(1,2))\n",
    "df_train['zcr_mean'] = np.mean(zcr, axis=(1,2))\n",
    "df_train['zcr_std'] = np.std(zcr, axis=(1,2))\n",
    "for j in range(0, 20):\n",
    "    df_train[f' mfcc_mean{j}'] = np.mean(mfcc[:,j,:], axis=1)\n",
    "    df_train[f' mfcc_std{j}'] = np.std(mfcc[:,j,:], axis=1)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.to_pickle('./df_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('./df_train.pkl')\n",
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train[[c for c in df_train.columns if c not in ['filename', 'audiotype']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:,2:], dtype = float))\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining target\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data['instrument'])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting of dataset into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)\n",
    "                    \n",
    "# calculate accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print('test_acc: ',test_acc)\n",
    "\n",
    "# predictions\n",
    "predictions = model.predict(X_test)\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = '../data/kaggle-test/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "files = os.listdir(testpath)\n",
    "stft = []\n",
    "rmse = []\n",
    "spec_cent = []\n",
    "spec_bw = []\n",
    "rolloff = []\n",
    "zcr = []\n",
    "mfcc = []\n",
    "\n",
    "for f in files:\n",
    "    filename = os.path.join(testpath, str(f))\n",
    "    y, sr = librosa.load(filename, mono=True, duration=120)\n",
    "    stft.append(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    rmse.append(librosa.feature.rms(y=y))\n",
    "    spec_cent.append(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spec_bw.append(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    rolloff.append(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    zcr.append(librosa.feature.zero_crossing_rate(y))\n",
    "    mfcc.append(librosa.feature.mfcc(y=y, sr=sr))\n",
    "    \n",
    "stft = np.array(stft)\n",
    "rmse = np.array(rmse)\n",
    "spec_cent = np.array(spec_cent)\n",
    "rolloff = np.array(rolloff)\n",
    "zcr = np.array(zcr)\n",
    "mfcc = np.array(mfcc)\n",
    "    \n",
    "print(\"Extracting the features took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(files, columns=['id'])\n",
    "df_predict['id'] = df_predict['id'].str.extract(pat = '([0-9]*).wav')\n",
    "df_predict['id'] = pd.to_numeric(df_predict['id'])\n",
    "#df_predict['instrument'] = df_predict['filename'].str.extract(pat = '^([a-z]*)_')\n",
    "df_predict['chroma_stft_mean'] = np.mean(stft, axis=(1,2))\n",
    "df_predict['chroma_stft_std'] = np.std(stft, axis=(1,2))\n",
    "df_predict['rmse_mean'] = np.mean(rmse, axis=(1,2))\n",
    "df_predict['rmse_std'] = np.std(rmse, axis=(1,2))\n",
    "df_predict['spec_cent_mean'] = np.mean(spec_cent, axis=(1,2))\n",
    "df_predict['spec_cent_std'] = np.std(spec_cent, axis=(1,2))\n",
    "df_predict['spec_bw_mean'] = np.mean(spec_bw, axis=(1,2))\n",
    "df_predict['spec_bw_std'] = np.std(spec_bw, axis=(1,2))\n",
    "df_predict['rolloff_mean'] = np.mean(rolloff, axis=(1,2))\n",
    "df_predict['rolloff_std'] = np.std(rolloff, axis=(1,2))\n",
    "df_predict['zcr_mean'] = np.mean(zcr, axis=(1,2))\n",
    "df_predict['zcr_std'] = np.std(zcr, axis=(1,2))\n",
    "for j in range(0, 20):\n",
    "    df_predict[f' mfcc_mean{j}'] = np.mean(mfcc[:,j,:], axis=1)\n",
    "    df_predict[f' mfcc_std{j}'] = np.std(mfcc[:,j,:], axis=1)\n",
    "    \n",
    "df_predict.sort_values(by='id', inplace=True)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.dropna(inplace=True)\n",
    "testdata = df_predict[[c for c in df_predict.columns if c not in ['id']]]\n",
    "X = scaler.fit_transform(np.array(testdata.iloc[:,1:], dtype = float))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "familyPredictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SVM-time-submission.csv', 'w', newline='') as writeFile:\n",
    "    fieldnames = ['Id', 'Predicted']\n",
    "    writer = csv.DictWriter(writeFile, fieldnames=fieldnames, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writeheader()\n",
    "    for index in range(len(testDataset)):\n",
    "        writer.writerow({'Id': index, 'Predicted': familyPredictionStrings[index]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
